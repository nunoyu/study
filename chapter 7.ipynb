{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import gauss\n",
    "import pickle\n",
    "path = 'd:/largedata/'\n",
    "pkl_file = open(path + 'data.pkl', 'w') #没有该文件的情况下，open等同于建立一个文件。文件格式为pkl\n",
    "a = [gauss(1.5, 2) for i in range(1000000)]  #创建一个随机list\n",
    "%time pickle.dump(a, pkl_file) #将变量a存到刚刚建立的data.pkl文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = [gauss(1.5, 2) for i in range(100)] #加一个c list到文件里\n",
    "pickle.dump(b, pkl_file) #pickle文件遵从FIFO\n",
    "pkl_file.close() #关闭打开的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.30079613979488107,\n",
       " 5.193282929685644,\n",
       " -1.168491788957502,\n",
       " 2.2509418067156934,\n",
       " 1.2985729272162072]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:5] #c存在于内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0276979023221577,\n",
       " 1.750399200021402,\n",
       " 2.2558436851464325,\n",
       " 4.1896720985865725,\n",
       " 3.5204604626987512]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file = open(path + 'data.pkl', 'r')\n",
    "c = pickle.load(pkl_file) #难道整个data.pkl文件就只存一个list? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0276979023221577,\n",
       " 1.750399200021402,\n",
       " 2.2558436851464325,\n",
       " 4.1896720985865725,\n",
       " 3.5204604626987512]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:5] #data里面存了a和c, 但是b只调用了a。因为是FIFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.array(a), np.array(c)) #内建方法，检查两个数组是否完全一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(a) - np.array(c)) #用差值检验是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.30079613979488107,\n",
       " 5.193282929685644,\n",
       " -1.168491788957502,\n",
       " 2.2509418067156934,\n",
       " 1.2985729272162072]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:5] #第二次，调用的就是第二个数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file = open(path + 'data.pkl', 'w')\n",
    "x = np.array(a)\n",
    "y = np.array(b) ** 2 \n",
    "pickle.dump({'x':x, 'y':y}, pkl_file) # 为了便于提取，使用字典方式储存。此外，如果调用narray，储存的速度大幅提高\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y [  0.09047832  26.97018759   1.36537306   5.06673902   1.68629165]\n",
      "x [ 1.0276979   1.7503992   2.25584369  4.1896721   3.52046046]\n"
     ]
    }
   ],
   "source": [
    "pkl_file = open(path + 'data.pkl', 'r')\n",
    "data = pickle.load(pkl_file) #调入内存\n",
    "pkl_file.close() #立刻关闭\n",
    "for key in data.keys(): #调用所有的key，做循环\n",
    "    print key, data[key][:5]  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5983, -0.819 ,  0.786 , -0.3057, -0.1253],\n",
       "       [ 0.0369,  0.7771, -1.3399,  0.5086,  0.6775],\n",
       "       [ 1.9616, -0.7722, -0.5733,  0.4304,  1.0151],\n",
       "       ..., \n",
       "       [-0.1843, -0.3269,  0.1538, -0.0544,  0.8309],\n",
       "       [ 0.3522,  0.4436,  1.4097,  0.3011, -0.7767],\n",
       "       [-0.7807, -0.6547, -0.8556, -0.7168, -0.7116]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = 5000\n",
    "a = np.random.standard_normal((rows,5)) #建立随机数组\n",
    "a.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-01-01 00:00:00', '2015-01-01 01:00:00',\n",
       "               '2015-01-01 02:00:00', '2015-01-01 03:00:00',\n",
       "               '2015-01-01 04:00:00', '2015-01-01 05:00:00',\n",
       "               '2015-01-01 06:00:00', '2015-01-01 07:00:00',\n",
       "               '2015-01-01 08:00:00', '2015-01-01 09:00:00',\n",
       "               ...\n",
       "               '2015-07-27 22:00:00', '2015-07-27 23:00:00',\n",
       "               '2015-07-28 00:00:00', '2015-07-28 01:00:00',\n",
       "               '2015-07-28 02:00:00', '2015-07-28 03:00:00',\n",
       "               '2015-07-28 04:00:00', '2015-07-28 05:00:00',\n",
       "               '2015-07-28 06:00:00', '2015-07-28 07:00:00'],\n",
       "              dtype='datetime64[ns]', length=5000, freq='H')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t = pd.date_range(start='2015/1/1', periods=rows, freq='H', )  #建立一个世界序列datetime以便加到前面数组做序列\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = open(path + 'data.csv', 'w') #建立一个csv，可写模式打开\n",
    "header = 'date,no1,no2,no3,no4,no5\\n' #csv是文本文件，所以用字符串写，之间也on用逗号连接. \\n用于换行\n",
    "csv_file.write(header) #写入第一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t_, (no1, no2, no3, no4, no5) in zip(t, a):\n",
    "    s = '%s,%f,%f,%f,%f,%f\\n' %(t_, no1, no2, no3, no4, no5) #因为是csv所以都是字符串\n",
    "    csv_file.write(s)\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,no1,no2,no3,no4,no5\n",
      "\n",
      "2015-01-01 00:00:00,-0.598254,-0.819003,0.785989,-0.305708,-0.125315\n",
      "\n",
      "2015-01-01 01:00:00,0.036851,0.777115,-1.339946,0.508609,0.677543\n",
      "\n",
      "2015-01-01 02:00:00,1.961592,-0.772161,-0.573284,0.430400,1.015129\n",
      "\n",
      "2015-01-01 03:00:00,0.422487,-1.142960,0.652941,1.593178,-0.152227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = open(path + 'data.csv', 'r')\n",
    "content = csv_file.readlines() #d读取文件\n",
    "csv_file.close() #调入内存后关闭文件\n",
    "for line in content[:5]:\n",
    "    print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
